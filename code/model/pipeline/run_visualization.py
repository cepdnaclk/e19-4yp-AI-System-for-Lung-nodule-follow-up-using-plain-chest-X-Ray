"""
Complete example of using visualization tools for lung nodule segmentation model.
Run this script to generate comprehensive visualizations of your model's performance.
"""

import torch
import numpy as np
import os
from torch.utils.data import DataLoader
import torchxrayvision as xrv

# Import your modules
from visualization import ModelVisualizer, visualize_dataset_statistics
from drr_dataset_loading import DRRSegmentationDataset
from custom_model import ImprovedXrayDRRSegmentationModel
from config_ import Config

def main():
    """Main visualization analysis function."""
    
    # Setup
    config = Config()
    device = config.DEVICE
    print(f"ðŸš€ Using device: {device}")
    
    # Create results directory
    os.makedirs('results', exist_ok=True)
    
    # Load dataset
    print("ðŸ“Š Loading dataset...")
    try:
        dataset = DRRSegmentationDataset(
            root_dir=config.DATA_ROOT,
            image_size=config.IMAGE_SIZE
        )
        print(f"âœ… Dataset loaded: {len(dataset)} samples")
    except Exception as e:
        print(f"âŒ Error loading dataset: {e}")
        return
    
    # Create validation split (use same split as training)
    train_size = int(config.TRAIN_SPLIT * len(dataset))
    val_size = len(dataset) - train_size
    _, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=config.BATCH_SIZE, 
        shuffle=False,
        num_workers=2
    )
    print(f"âœ… Validation set: {len(val_dataset)} samples")
    
    # Load trained model
    print("ðŸ¤– Loading trained model...")
    try:
        checkpoint_path = os.path.join(config.SAVE_DIR, 'best_model.pth')
        if not os.path.exists(checkpoint_path):
            print(f"âŒ Model checkpoint not found at: {checkpoint_path}")
            print("ðŸ’¡ Make sure you have trained the model first using:")
            print("   python improved_train.py")
            return
            
        checkpoint = torch.load(checkpoint_path, map_location=device)
        pretrained_model = xrv.models.ResNet(weights=config.PRETRAINED_WEIGHTS)
        model = ImprovedXrayDRRSegmentationModel(
            pretrained_model,
            alpha=config.ALPHA,
            use_channel_attention=config.USE_CHANNEL_ATTENTION
        )
        model.load_state_dict(checkpoint['model_state_dict'])
        model = model.to(device)
        model.eval()
        
        print(f"âœ… Model loaded successfully!")
        print(f"ðŸ“ˆ Best validation Dice: {checkpoint.get('best_dice', 'N/A'):.4f}")
        
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        return
    
    # Create visualizer
    visualizer = ModelVisualizer(model, device)
    
    # Get sample data
    print("ðŸ” Preparing sample data...")
    try:
        sample_batch = next(iter(val_loader))
        xray = sample_batch["xray"].to(device)
        drr = sample_batch["drr"].to(device)
        mask = sample_batch["mask"].to(device)
        print(f"âœ… Sample batch loaded: {xray.shape}")
    except Exception as e:
        print(f"âŒ Error loading sample data: {e}")
        return
    
    print("\nðŸŽ¨ Starting comprehensive visualization analysis...")
    print("=" * 60)
    
    # 1. Attention mechanism analysis
    print("1ï¸âƒ£ Analyzing attention mechanism...")
    try:
        visualizer.visualize_attention_mechanism(
            xray=xray, drr=drr, mask=mask,
            save_path='results/attention_analysis.png'
        )
        print("   âœ… Attention analysis saved to results/attention_analysis.png")
    except Exception as e:
        print(f"   âŒ Error in attention analysis: {e}")
    
    # 2. Prediction quality analysis
    print("\n2ï¸âƒ£ Analyzing prediction quality across samples...")
    try:
        metrics = visualizer.analyze_prediction_quality(
            dataloader=val_loader,
            num_samples=16,
            save_path='results/quality_analysis.png'
        )
        print("   âœ… Quality analysis saved to results/quality_analysis.png")
        
        # Print summary
        print("   ðŸ“Š Performance Summary:")
        for metric, values in metrics.items():
            print(f"      {metric.title()}: {np.mean(values):.4f} Â± {np.std(values):.4f}")
            
    except Exception as e:
        print(f"   âŒ Error in quality analysis: {e}")
    
    # 3. Threshold optimization
    print("\n3ï¸âƒ£ Optimizing prediction threshold...")
    try:
        threshold_metrics, optimal_threshold = visualizer.threshold_analysis(
            dataloader=val_loader,
            save_path='results/threshold_analysis.png'
        )
        print("   âœ… Threshold analysis saved to results/threshold_analysis.png")
        print(f"   ðŸŽ¯ Recommended threshold: {optimal_threshold:.3f}")
        
    except Exception as e:
        print(f"   âŒ Error in threshold analysis: {e}")
        optimal_threshold = 0.5  # Default fallback
    
    # 4. Feature map visualization
    print("\n4ï¸âƒ£ Visualizing learned features...")
    try:
        visualizer.visualize_feature_maps(
            xray=xray, drr=drr,
            layer_name='layer4',
            save_path='results/feature_maps.png'
        )
        print("   âœ… Feature maps saved to results/feature_maps_layer4.png")
    except Exception as e:
        print(f"   âŒ Error in feature visualization: {e}")
    
    # 5. Dataset statistics
    print("\n5ï¸âƒ£ Analyzing dataset characteristics...")
    try:
        visualize_dataset_statistics(
            dataset=dataset,
            save_path='results/dataset_stats.png'
        )
        print("   âœ… Dataset statistics saved to results/dataset_stats.png")
    except Exception as e:
        print(f"   âŒ Error in dataset analysis: {e}")
    
    # Summary
    print("\n" + "=" * 60)
    print("ðŸŽ‰ Visualization analysis completed!")
    print("\nðŸ“ Generated files:")
    results_files = [
        "results/attention_analysis.png",
        "results/quality_analysis.png", 
        "results/threshold_analysis.png",
        "results/feature_maps_layer4.png",
        "results/dataset_stats.png"
    ]
    
    for file_path in results_files:
        if os.path.exists(file_path):
            print(f"   âœ… {file_path}")
        else:
            print(f"   âŒ {file_path} (failed to generate)")
    
    print(f"\nðŸŽ¯ Key Recommendations:")
    print(f"   â€¢ Use threshold: {optimal_threshold:.3f} for binary predictions")
    print(f"   â€¢ Check attention maps for proper nodule focus")
    print(f"   â€¢ Review quality analysis for model performance")
    
    print("\nðŸ’¡ Next steps:")
    print("   â€¢ Open the PNG files to review visualizations")
    print("   â€¢ If attention maps look poor, consider retraining") 
    print("   â€¢ If Dice scores are low, adjust loss function weights")
    print("   â€¢ Use the optimal threshold in your evaluation scripts")

def quick_attention_check():
    """Quick function to just check attention mechanism."""
    
    print("ðŸ” Quick Attention Check...")
    
    # Minimal setup
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # Load model
    try:
        pretrained_model = xrv.models.ResNet(weights="resnet50-res512-all")
        model = ImprovedXrayDRRSegmentationModel(pretrained_model)
        
        checkpoint = torch.load('checkpoints/best_model.pth', map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model = model.to(device)
        
        print("âœ… Model loaded")
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        return
    
    # Load single sample
    try:
        dataset = DRRSegmentationDataset(
            root_dir='../../../DRR dataset/LIDC_LDRI',
            image_size=(512, 512)
        )
        sample = dataset[0]
        
        xray = sample["xray"].unsqueeze(0).to(device)
        drr = sample["drr"].unsqueeze(0).to(device)
        mask = sample["mask"].unsqueeze(0).to(device)
        
        print("âœ… Sample loaded")
    except Exception as e:
        print(f"âŒ Error loading sample: {e}")
        return
    
    # Quick visualization
    visualizer = ModelVisualizer(model, device)
    visualizer.visualize_attention_mechanism(
        xray=xray, drr=drr, mask=mask,
        save_path='quick_attention_check.png'
    )
    
    print("âœ… Quick attention check saved to quick_attention_check.png")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--quick":
        quick_attention_check()
    else:
        main()
